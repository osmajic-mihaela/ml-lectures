{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. ÄŒiÅ¡Ä‡enje i priprema podataka**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Lc0EJzU0-dAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ğŸŒŸ **Analogija**  \n",
        "Zamislite da pravite salatu:  \n",
        "- Ako koristite **pokvareni paradajz** ili **neopranu zelenu salatu**, cela salata Ä‡e imati loÅ¡ ukus\n",
        "**ÄŒiÅ¡Ä‡enje podataka je isto** â€“ ako model uÄi iz neurednih podataka, donosiÄ‡e loÅ¡e odluke.  \n",
        "**Cilj**: Ukloniti 'neÄistoÄ‡e' i pripremiti podatke da budu **konzistentni, potpuni i korisni**.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“š **Definicija**  \n",
        "Proces transformacije \"sirovih\" podataka u oblik pogodan za maÅ¡insko uÄenje.\n",
        "\n",
        "**KljuÄni koraci**:  \n",
        "1. **Popunjavanje nedostajuÄ‡ih vrednosti** (Missing Values).  \n",
        "2. **Uklanjanje autlajera** (Outliers).  \n",
        "3. **Kodiranje kategorijskih promenljivih** .  \n",
        "4. **Normalizacija** (skaliranje brojeva na zajedniÄki opseg).  \n",
        "5. **Uklanjanje duplikata**.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§¹ **Koraci ÄiÅ¡Ä‡enja i pripreme (sa primerima)**  \n",
        "\n",
        "#### 1. **NedostajuÄ‡i podaci (Missing Values)**  \n",
        "- **Problem**: Prazna polja u tabeli (`NaN`).  \n",
        "- **ReÅ¡enja**:  \n",
        "  - **Popuniti ih**: npr. srednjom vrednoÅ¡Ä‡u, medijanom, interpolacijom, vrednoÅ¡Ä‡u najsliÄnije instance...\n",
        "  - **Izbaciti redove**: Ako je mali procenat nedostajuÄ‡ih vrednosti   \n",
        "\n",
        "\n",
        "#### 2. **Autlajeri (Outliers)**  \n",
        "- **Problem**: Vrednosti koje ekstremno odstupaju (npr. stan od 200 mÂ² u gradu gde su proseÄni stanovi 70 mÂ²).  \n",
        "- **ReÅ¡enja**:  \n",
        "  - **Izbaciti ih**: Ako su greÅ¡ke (npr. pogreÅ¡no uneta vrednost).  \n",
        "  - **Zameniti graniÄnim vrednostima**: Npr. postaviti maksimum na 100 mÂ².  \n",
        "\n",
        "#### 3. **Kodiranje kategorijskih promenljivih**  \n",
        "- **Problem**: Modeli ne razumeju tekst (npr. \"Beograd\", \"Novi Sad\").  \n",
        "- **ReÅ¡enja**:  \n",
        "  - **Label Encoding**: \"Beograd\" â†’ 1, \"Novi Sad\" â†’ 2.  \n",
        "  - **One-Hot Encoding**: Svaka kategorija postaje posebna binarna vrednost (0 ili 1) u nizu (vektoru) svih vrednosti. Za dva moguÄ‡a grada Beograd i Novi Sad, Beograd moÅ¾emo predstaviti kao [1,0], a Novi Sad kao [0, 1]. Generalno, svaka vrednost je predstavljena vektorom gde je na njemu odgovarajuÄ‡oj poziciji 1, a na ostalim pozicijama je 0. ->  (Beograd: [1,0], Novi Sad: [1,0]).  \n",
        "- *Prevodite reÄi na jezik koji raÄunar razume (brojeve).*  \n",
        "\n",
        "#### 4. **Normalizacija**  \n",
        "- **Problem**: RazliÄiti opsezi (npr. kvadratura: 50â€“200 mÂ², cena: 50.000â€“500.000â‚¬).  \n",
        "- **ReÅ¡enje**: Skalirajte sve brojeve na opseg 0â€“1.  \n",
        "- **Analogija**: *Kao da sve sastojke iseÄete na sliÄnu ili srazmernu veliÄinu da ravnomerno proÄ‘u kroz proces kuvanja.*  \n",
        "\n",
        "#### 5. **Duplikati**  \n",
        "- **Problem**: Isti podaci uneti viÅ¡e puta.  \n",
        "- **ReÅ¡enje**: Izbacivanje ponavljanja.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’¡ **ZaÅ¡to je ovaj proces bitan?**  \n",
        "1. **TaÄnost modela**:  \n",
        "   - *LoÅ¡i podaci â†’ LoÅ¡a predviÄ‘anja.* - *Garbage in, garbage out*\n",
        "   - *Primer:* Ako model vidi da neki stanovi imaju kvadraturu 0 mÂ², nauÄiÄ‡e pogreÅ¡ne veze.  \n",
        "\n",
        "2. **Brzina i efikasnost**:  \n",
        "   - ÄŒist skup podataka smanjuje vreme obuke i memorijsko optereÄ‡enje.  \n",
        "\n",
        "3. **SpreÄavanje pristrasnosti (Bias)**:  \n",
        "   - Ako podaci sadrÅ¾e sistematske greÅ¡ke (npr. svi stanovi su iz jednog naselja), model Ä‡e biti pristrasan.  \n",
        "\n",
        "4. **Generalizacija**:  \n",
        "   - Dobro pripremljeni podaci omoguÄ‡avaju modelu da radi i na **novim podacima**.  \n",
        "---\n",
        "\n",
        "### ğŸŒ **Primer iz prakse: PredviÄ‘anje cena automobila**  \n",
        "1. **NedostajuÄ‡i podaci**: 10% automobila nema godiÅ¡te â†’ zameni medianom (2015).  \n",
        "2. **Autlajeri**: Jedan automobil ima godiÅ¡te 3021 (oÄigledna greÅ¡ka) â†’ izbaci.  \n",
        "3. **Kategorijska promenljiva**: Boja â†’ One-Hot Encoding\n",
        "4. **Skaliranje**: Cena od 5.000â€“50.000â‚¬ â†’ skaliraj na 0â€“1.  \n",
        "\n",
        "**Efekat**: Model postaje taÄniji nakon ÄiÅ¡Ä‡enja!  \n",
        "\n",
        "---\n",
        "\n",
        "###  \n",
        "```  \n",
        "PRE ÄŒIÅ Ä†ENJA:  \n",
        "| Model   | GodiÅ¡te | Cena   | Boja   |  \n",
        "|---------|---------|--------|--------|  \n",
        "| Golf    | 2010    | 8000   | Crvena |  \n",
        "| Passat  | NaN     | 15000  | Plava  |  \n",
        "| Polo    | 3021    | 500    | Crna   |  \n",
        "\n",
        "POSLE ÄŒIÅ Ä†ENJA:  \n",
        "| Model   | GodiÅ¡te | Cena (0-1) | Crvena | Plava | Crna   |  \n",
        "|---------|---------|------------|--------|-------|--------|  \n",
        "| Golf    | 2010    | 0.16       | 1      | 0     | 0      |  \n",
        "| Passat  | 2015    | 0.30       | 0      | 1     | 1      |  \n",
        "```  \n",
        "\n",
        "---\n",
        "\n",
        "### â“ **Interaktivno pitanje**  \n",
        "*Å ta biste uradili sa kolonom gde 50% podataka nedostaje?*  \n",
        "- **A)** Izbaciti celu kolonu.  \n",
        "- **B)** Popuniti prosekom.  \n",
        "- **C)** IstraÅ¾iti zaÅ¡to nedostaje i doneti odluku.\n",
        "- **D)** Izbaciti sve redove sa nedostajuÄ‡im vrednostima.\n",
        "<details>\n",
        "  <summary>Klikni za odgovor</summary>\n",
        "  âœ…  C â€“ kontekst je kljuÄan!\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸš« **ÄŒeste greÅ¡ke**  \n",
        "1. **PreviÅ¡e ÄiÅ¡Ä‡enja**: Uklanjanje autlajera koji su zapravo validni (npr. retki ali vaÅ¾ni sluÄajevi prevara).  \n",
        "2. **Ignorisanje konteksta**: Popunjavanje nedostajuÄ‡ih vrednosti na naÄin koji iskrivljuje priÄu (npr. zameniti nedostajuÄ‡u platu prosekom, iako su podaci grupisani po radnim mestima).  \n",
        "3. **Zanemariti nebalansiranost skupova**: Ako su klase nejednako zastupljene (npr. 95% pozitivnih i 5% negativnih primera), model moÅ¾e nauÄiti da uvek predviÄ‘a dominantnu klasu, Å¡to dovodi do loÅ¡e generalizacije.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qthxj19884fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Princip evaluacije:**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "qqoPW7E4-lwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Napomena: Pri obuÄavanju modela uporeÄ‘ujemo stvarne i predviÄ‘ene vrednosti modela i dobijamo kvantitativnu vrednost performansi modela - meru performanse (ViÅ¡e o tome u nastavku), ali pre obuÄavanja moramo skup podataka da podelimo na grupe shodno njihovim svrhama.    \n",
        "U literaturi princip evaluacije i mera performanse se uglavnom nalaze pod naslovom \"Evaluacija modela\". Kako bismo ispratili tok rada jednog ML projekta mi Ä‡emo prvo priÄati o principu evaluacije kao procesu podele skupa podataka, onda o obuÄavanju, a nakon toga o merama perfomanse modela.\n",
        "\n",
        "### ğŸŒŸ **Analogija**  \n",
        "*Zamislite da uÄite za ispit iz matematike:*  \n",
        "- **Trening skup**: UdÅ¾benik iz kog veÅ¾bate.  \n",
        "- **Validacioni skup**: Probni testovi koje radite pre ispita da proverite gde greÅ¡ite.  \n",
        "- **Test skup**: Sam ispit â€“ provera na zadacima koje do tad niste videli, tek tu vidite koliko ste stvarno nauÄili.  \n",
        "\n",
        "**Cilj:** Provera generalizacije modela - da li radi i na **novim, neviÄ‘enim podacima** (a ne samo na onima koje je 'nauÄio napamet').\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“š **Definicija**  \n",
        "\n",
        "U nastavku Ä‡emo navesti dva najÄeÅ¡Ä‡a principa evaluacije (podele svih raspoloÅ¾ivih primera iz skupa podataka):\n",
        "\n",
        "#### 1. **Trening/Validacioni/Test skup**  \n",
        "- **Trening skup** (70â€“80% podataka):  \n",
        "  - Podaci na kojima model **uÄi** (nalazi obrasce).  \n",
        "  - *Analogija:* VeÅ¾banje zadataka iz udÅ¾benika.  \n",
        "- **Validacioni skup** (10â€“15%):  \n",
        "  - Podaci za **podeÅ¡avanje** modela (odabir najboljih hiperparametara).  \n",
        "  - *Analogija:* Probni testovi â€“ menjate strategiju uÄenja ako rezultati nisu zadovoljavajuÄ‡i.  \n",
        "- **Test skup** (10â€“15%):  \n",
        "  -  Podaci za **finalnu proveru** performansi.  \n",
        "  - *Analogija:* Ispit u realnim uslovima â€“ test znanja na nikad viÄ‘enim podacima.  \n",
        "\n",
        "```  \n",
        "Podaci â†’ [Trening (70%)] â†’ [Validacioni (15%)] â†’ [Test (15%)]  \n",
        "```\n",
        "\n",
        "\n",
        "#### 2. **K-unakrsna validacija (K-Fold Cross-Validation)**  \n",
        "- Podela podataka na **K jednakih delova**. Model se trenira **K puta** â€“ svaki put se jedan deo koristi za validaciju, ostali za trening.  \n",
        "- **Analogija:**  \n",
        "  Postoji 5 probnih testova. Svaki put izaberete 1 test da radite, a ostala 4 koristite za uÄenje. Na kraju, uproseÄite rezultate svih 5 testova.  \n",
        "\n",
        "```  \n",
        "K = 5  \n",
        "1. Iteracija: Trening (Fold 2-5) â†’ Validacija (Fold 1)  \n",
        "2. Iteracija: Trening (Fold 1,3-5) â†’ Validacija (Fold 2)  \n",
        "...  \n",
        "5. Iteracija: Trening (Fold 1-4) â†’ Validacija (Fold 5)  \n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ **KljuÄne razlike izmeÄ‘u metoda**  \n",
        "| Metoda               | Prednosti                          | Nedostaci                     | Kada koristiti?              |  \n",
        "|----------------------|------------------------------------|-------------------------------|------------------------------|  \n",
        "| **Trening/Valid/Test** | BrÅ¾a i jednostavnija.             | Manje pouzdana ako je malo podataka. | Veliki skupovi podataka.     |  \n",
        "| **K-Fold**           | Smanjuje rizik od loÅ¡e podele podataka. | Spora i zahteva viÅ¡e resursa. | Mali skupovi ili kritiÄni zadaci. |  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸŒ **Primer**  \n",
        "\n",
        "Pravite model za prepoznavanje bolesti na osnovu rendgena:\n",
        "\n",
        "1. **Trening skup**: 800 slika â€“ model uÄi kako izgledaju obolela i zdrava tkiva.  \n",
        "2. **Validacioni skup**: 100 slika â€“ podeÅ¡avate parametre (spreÄavate preprilagodavanje, tj. napamet situaciju napamet nauÄenih 800 slika - overfitting (O tome viÅ¡e u sledeÄ‡em poglavlju)).  \n",
        "3. **Test skup**: 100 slika â€“ konaÄno merenje koliko je model pouzdan.\n",
        "\n",
        "SpreÄava preprilagodavanje i daje realnu sliku performansi\n",
        "\n",
        "**K-Fold (K=5):**  \n",
        "- Podelite 1000 slika na 5 grupa.  \n",
        "- Svaka grupa je validacioni skup taÄno jednom.  \n",
        "- ProseÄna taÄnost svih 5 testova = realnija procena.  \n",
        "\n",
        "\"Zlatni standard\" za male skupove â€“ svaki podatak dobije ulogu u treningu i validaciji.\n",
        "\n",
        "---\n",
        "\n",
        "### â“ **Interaktivno pitanje**  \n",
        "*Å ta biste odabrali za ove situacije?*  \n",
        "- **A)** Imate 100.000 podataka i Å¾elite brzu evaluaciju.  \n",
        "<details>\n",
        "  <summary>Klikni za odgovor</summary>\n",
        "  âœ…  Trening/Valid/Test\n",
        "</details>\n",
        "- **B)** Imate samo 500 podataka i Å¾elite maksimalno pouzdane rezultate.  \n",
        "<details>\n",
        "  <summary>Klikni za odgovor</summary>\n",
        "  âœ…  K-Fold\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸš« **ÄŒeste greÅ¡ke**  \n",
        "1. **Testiranje na trening podacima**: Koristite udÅ¾benik kao ispit â€“ model Ä‡e imati laÅ¾no visoke performanse.  \n",
        "2. **Curenje podataka (Data Leakage)**: SluÄajno koriÅ¡Ä‡enje test podataka za podeÅ¡avanje modela â€“ videli ste ispit pre nego Å¡to ga radite.  \n",
        "\n"
      ],
      "metadata": {
        "id": "YJBvWF_mxb6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. ObuÄavanje modela**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uboQR-eZ-pxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ğŸŒŸ **Analogija**  \n",
        "*Zamislite da uÄite studenta matematike:*\n",
        "1. **Delite zadatke u tri kategorije** : za uÄenje (trening skup), za proveru (validacioni skup) i za krajnje testiranje (test skup)\n",
        "2. **Zadatke iz udÅ¾benika (trening podaci) delite na lekcije (batch-eve)**  \n",
        "2. **Proveravate reÅ¡enja** i objaÅ¡njavate greÅ¡ke (validacioni skup).  \n",
        "3. **Ponavljate** dok ne nauÄi (epohu po epohu ).  \n",
        "4. **Testirate ga na novim zadacima** (test skup).  \n",
        "\n",
        "**Treniranje modela je isto** â€“ algoritam 'uÄi' iz podataka da bi donosio taÄna predviÄ‘anja.\n",
        "\n",
        "---\n",
        "\n",
        "Pre svega potrebno je izabrati model, cilj obuÄavanja modela je uÄenje parametra koji Ä‡e za novi podatak dati Å¡to taÄniju izlaznu vrednost.\n",
        "\n",
        "\n",
        "### ğŸ“š **Å ta se deÅ¡ava tokom obuÄavanja?**  \n",
        "1. **Model prima podatke**:  \n",
        "   - **ObeleÅ¾ja (X)**: Ulazne informacije (npr. kvadratura, lokacija stana).  \n",
        "   - **Labela (y)**: Izlaz koji Å¾elimo da predvidi (npr. cena stana).  \n",
        "\n",
        "2. **Inicijalizacija parametara**:  \n",
        "   - Model poÄinje sa **nasumiÄnim pretpostavkama** (npr. teÅ¾inski koeficijenti u linearnoj regresiji).  \n",
        "   - *Analogija:* Zamislite da je student pre bilo kakvog uÄenja osmislio svoju metodu reÅ¡avanja zadataka.  \n",
        "\n",
        "3. **PredviÄ‘anje i greÅ¡ka**:  \n",
        "  - Model vrÅ¡i proces **predviÄ‘anja** (npr. cena = 200.000â‚¬).  \n",
        "  - **GreÅ¡ka (loss)** se raÄuna poreÄ‘enjem sa stvarnom vrednoÅ¡Ä‡u instance iz trening skupa (npr. stvarna cena = 210.000â‚¬ â†’ greÅ¡ka = 10.000â‚¬).  \n",
        "  - Ujedno se proverava i mera performanse na validacionom skupu.\n",
        "  - *Analogija:* Student prelazi lekciju iz udÅ¾benik. Nakon Å¡to je nauÄi, proverava svoje znanje na zadacima za proveru.  \n",
        "\n",
        "4. **Optimizacija**:  \n",
        "   - Model **podeÅ¡ava parametre** kako bi smanjio greÅ¡ku kojim neznatno menja vrednost parametra u smeru koji smanjuje greÅ¡ku rezultata (npr. koristi **gradijentni spust**).  \n",
        "   - *Analogija:* Student prilagodi metode reÅ¡avanja nakon Å¡to vidi gde greÅ¡i.\n",
        "\n",
        "  ğŸš© **Napomena** : Model podeÅ¡ava parametre u odnosu na greÅ¡ke sa trening skupa, provera na validacionom skupu je provera koliko model greÅ¡i u **generalizaciji** (sposobnost modela da uspeÅ¡no primeni nauÄeno i na novim situacijama, a ne samo na onim Å¡to je veÄ‡ \"zapamtio\").\n",
        "\n",
        "   GreÅ¡ke na trening skupu sluÅ¾e za obuÄavanje modela, tj. podeÅ¡avanje parametara. PraÄ‡enje greÅ¡ke na validacionom skupu sluÅ¾i za podeÅ¡avanje hiperparametara modela koje korisnik nameÅ¡ta ruÄno pre poÄetka obuÄavanja.\n",
        "\n",
        "  1) **Parametri** - raÄunaju se sami, podeÅ¡avaju pomoÄ‡u algoritma koji se oslanja na greÅ¡ku na trening skupu  \n",
        "  2) **Hiperparametri** - korisnik nameÅ¡ta pre poÄetka obuÄavanja, ukoliko je veÄ‡ obuÄio model oslanja se na rezultate sa validacionog skupa (JoÅ¡ jedna napomena: I ovaj proces se automatizuje, ali nekad to nije moguÄ‡e to uraditi zbog resursa. Kako bi Vam lakÅ¡e bilo da razumete razliku, ostanimo pri tome da korisnik to sam radi)\n",
        "\n",
        "5. **Ponavljanje (epohe)**:  \n",
        "   - Proces uÄenja se ponavlja ispoÄetka, dok greÅ¡ka ne postane dovoljno mala ili se dostigne maksimalan broj epoha.  \n",
        "\n",
        "6. **Testiranje**  \n",
        "   - Testiramo model na test podacima koje Ä‡e videti po prvi put.  \n",
        "\n",
        "---\n",
        "\n",
        "### âš™ï¸ **Kako model postaje bolji?**  \n",
        "- **Parametri se fino podeÅ¡avaju**: Svaka epoha smanjuje greÅ¡ku.  \n",
        "- **Primer za linearnu regresiju**:  \n",
        "  - PoÄetak: `cena = 3 * kvadratura + 10000` (loÅ¡e).  \n",
        "  - Kraj: `cena = 2.5 * kvadratura + 15000` (taÄnije).  \n",
        "\n",
        "  `2.5` i `15000` su nauÄeni parametri modela, `kvadratura` je atribut/obeleÅ¾je (x), `cena` je izlaz/labela/ciljno obeleÅ¾je (y)\n",
        "\n",
        "```  \n",
        "Korak 1: Inicijalizacija  \n",
        "Model: cena = 3 * kvadratura + 10000 â†’ greÅ¡ka = 50.000  \n",
        "\n",
        "Korak 2: PodeÅ¡avanje teÅ¾ina  -> epoha 1\n",
        "Model: cena = 2.8 * kvadratura + 12000 â†’ greÅ¡ka = 30.000  \n",
        "\n",
        "Korak 3: Ponavljanje  -> epoha 2\n",
        "Model: cena = 2.5 * kvadratura + 15000 â†’ greÅ¡ka = 10.000  \n",
        "```  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **KljuÄni koncepti u procesu**  \n",
        "\n",
        "#### 1. **Loss Function (Funkcija greÅ¡ke)**  \n",
        "- Metrika koja meri koliko su predviÄ‘anja loÅ¡a poreÄ‘enjem izraÄunate i stvarne izlazne vrednosti.  \n",
        "- **Primeri**:  \n",
        "  - **MSE** (Mean Squared Error): Za regresiju â€“ proseÄna kvadratna greÅ¡ka.  \n",
        "  - **Cross-Entropy**: Za klasifikaciju â€“ kaÅ¾njava pogreÅ¡ne klasifikacije.   \n",
        "\n",
        "#### 2. **Optimizacija (Gradijentni spust)**  \n",
        "- Algoritam koji pronalazi **minimum funkcije greÅ¡ke** podeÅ¡avanjem parametara.  \n",
        "- **Kako radi**:  \n",
        "  1. RaÄuna **gradijent** (nagib funkcije greÅ¡ke).  \n",
        "  2. Pomeri parametre u smeru suprotnom od gradijenta (npr. \"nizbrdo\").  \n",
        "- **Analogija**: Zamislite da se spuÅ¡tate niz brdo u magli â€“ pratite nagib (gradijent) da biste stigli do dna (minimalne greÅ¡ke).  \n",
        "\n",
        "*ViÅ¡e o tome u narednim lekcijama*\n",
        "\n",
        "#### 3. **Epohe i Batch-evi**  \n",
        "- **Epoha**: Jedan prolazak kroz **ceo trening skup**.  (npr. 3,168 primera)\n",
        "- **Batch**: Manji podskup podataka koriÅ¡Ä‡en u jednoj iteraciji (npr. 32 primera).  \n",
        "- **Analogija**:  \n",
        "  - **Epoha**: ProÄitati ceo udÅ¾benik jednom.  \n",
        "  - **Batch**: ProÄitati jednu lekciju.  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### ğŸš« **Izazovi tokom treniranja**  \n",
        "1. **Overfitting**: Model nauÄi napamet trening podatke (student koji je napamet nauÄio samo zadatke iz zbirke).  \n",
        "2. **Underfitting**: Model je previÅ¡e jednostavan (student koji ne razume osnove).  \n",
        "3. **Stagnacija**: GreÅ¡ka se ne pada i pored aÅ¾uriranja parametara â€“ moÅ¾da je potrebno promeniti model.  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸŒ **Primer: Prepoznavanje rukopisa**  \n",
        "1. **Ulaz**: Slika broja (28x28 piksela).  \n",
        "2. **Treniranje**:  \n",
        "   - Model uÄi da poveÅ¾e piksele sa brojevima (0-9).  \n",
        "   - Optimizuje teÅ¾ine da minimizuje greÅ¡ku.  \n",
        "3. **Rezultat**: Nakon 10 epoha, model taÄno prepoznaje 95% brojeva.  \n",
        "\n",
        "---\n",
        "\n",
        "### â“ **Interaktivno pitanje**  \n",
        "Å ta se desilo ako model ima izuzetno malu greÅ¡ku na trening skupu, ali veliku na testu?\n",
        "  <details>\n",
        "    <summary>Klikni za odgovor</summary>\n",
        "    âœ…   Overfitting â€“ model ne moÅ¾e da generalizuje\n",
        "  </details>\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ **Sumirano**  \n",
        "```  \n",
        "UÄŒENJE = PRAVLJENJE I POPRAVLJANJE GREÅ AKA ğŸ“‰  \n",
        "1. Probaj â†’ 2. Izmeri greÅ¡ku â†’ 3. Podesi parametre â†’ 4. Ponovi dok ne savladaÅ¡.  \n",
        "```  \n",
        "\n"
      ],
      "metadata": {
        "id": "wySvhx0n9Kwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Overfitting i Underfitting**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GPDNJ22u-uDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ğŸŒŸ **Analogija**  \n",
        "*Zamislite da uÄite da crtate Äoveka:*  \n",
        "- **Underfitting**: Nacrtate ÄŒiÄa GliÅ¡u (previÅ¡e jednostavno, nema detalja).  \n",
        "- **Overfitting**: Nacrtate svaki detalj, ali samo za Äoveka kog ste videli â€“ ne moÅ¾ete nacrtati druge ljude.  \n",
        "\n",
        "**Cilj**: NaÄ‡i balans â€“ crteÅ¾ koji prepoznaje osobu, ali sa dovoljno detalja.\n",
        "\n",
        "---\n",
        "Pogledaj sliku ispod.\n",
        "\n",
        "### ğŸ“š **Underfitting (Potprilagodavanje)**  \n",
        "- Model je **previÅ¡e jednostavan** da uhvati obrasce u podacima.  \n",
        "- **Analogija**:  \n",
        "  - Kao da pokuÅ¡avate da reÅ¡ite matematiÄki problem samo sa osnovnim raÄunanjem.  \n",
        "  - Ili da pevate pesmu samo u jednom tonu â€“ nema dinamike.  \n",
        "- **Znaci**:  \n",
        "  - LoÅ¡e performanse i na **trening** i na **validacionom** skupu.  \n",
        "  - Model ne uÄi niÅ¡ta korisno.  \n",
        "- **Uzroci**:  \n",
        "  - Premalo sloÅ¾enosti (npr. linearni model za nelinearne podatke).  \n",
        "  - Premalo podataka za obuku.  \n",
        "  - Premalo obeleÅ¾ja.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“š **Overfitting (Preprilagodavanje)**  \n",
        "- Model **nauÄi Å¡um i detalje iz trening podataka** i ne moÅ¾e da generalizuje.  \n",
        "- **Analogija**:  \n",
        "  - Student uÄi napamet sve primere iz zbirke, ali ne razume kako da reÅ¡i novi zadatak.  \n",
        "  - Zapamtite svaki korak GPS navigacije za jednu rutu â€“ ako se promeni put, izgubljeni ste.  \n",
        "- **Znaci**:  \n",
        "  - SavrÅ¡ena taÄnost na **trening**, ali loÅ¡a na **validacionom**.  \n",
        "  - Model \"prati\" svaku taÄku u podacima.  \n",
        "- **Uzroci**:  \n",
        "  - PreviÅ¡e sloÅ¾en model.  \n",
        "  - Predugo puÅ¡ten proces obuÄavanja.  \n",
        "  - PreviÅ¡e obeleÅ¾ja.\n",
        "\n",
        "![img/1/overfitting-underfitting.jpg](img/1/overfitting-underfitting.jpg)\n",
        "\n",
        "*Regulacija je tehnika spreÄavanja overfitting-a dodatnim kaÅ¾njavanjem modela u loss funkciji, spreÄavajuÄ‡i na taj naÄin \"uÄenje napamet\"*\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“š **Bias-Variance Tradeoff**  \n",
        "**Bias** (pristrasnost) pokazuje koliko model pojednostavljuje problem â€“ da li model pravi previÅ¡e jake pretpostavke i ignoriÅ¡e vaÅ¾ne obrasce u podacima, ne uÄi dobro.   \n",
        "**Variance**  (varijansa) pokazuje koliko su predikcije modela osetljive na promene u trening podacima.\n",
        "\n",
        "- **Underfitting** = **Visok bias** (model pravi jake pretpostavke - pojednostavljuje).  \n",
        "- **Overfitting** = **Visoka varijansa** (model je previÅ¡e osetljiv na podatke - previÅ¡e se uklapa u podatke).  \n",
        "- **Balans**: Model koji uhvati prave obrasce (dovoljno se uklopi u podatke), a ignoriÅ¡e Å¡um.  \n",
        "\n",
        "**Analogija**:  \n",
        "*Kao da podesite radio antenu:*  \n",
        "- **Underfitting**: Antena hvata sve Å¡umove, ali nijedna stanica nije Äista.\n",
        "- **Overfitting**: Antena uhvati samo jednu stanicu, ali jasno.\n",
        "- Potrebno je naÄ‡i meru tako da se uhvati dovoljno stanica, sa dovoljnom Äistinom\n",
        "\n",
        "*Ako zamislimo previÄ‘anje modela kao pogaÄ‘anje u metu*\n",
        "1. Visok bias, niska varijansa â†’ PromaÅ¡uje metu, ali je precizan na pogreÅ¡nom mestu (Underfitting).\n",
        "2. Nizak bias, visoka varijansa â†’ Ponekad pogodi, ali su hici raÅ¡trkani (Overfitting).\n",
        "3. Visok bias, visoka varijansa â†’ NiÅ¡ta ne funkcioniÅ¡e (loÅ¡ model).\n",
        "4. Nizak bias, niska varijansa â†’ Idealna situacija!\n",
        "\n",
        "![img/1/bias-variance.png](img/1/bias-variance.png)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ› ï¸ **Kako se boriti protiv ovih problema?**  \n",
        "#### Za **Underfitting**:  \n",
        "- **PoveÄ‡ajte sloÅ¾enost modela**: Koristite nelinearne modele (npr. neuronske mreÅ¾e).  \n",
        "- **Dodajte viÅ¡e obeleÅ¾ja**: Npr. ne samo \"kvadratura\", veÄ‡ i \"lokacija\", \"broj soba\".  \n",
        "- **Smanjite regularizaciju**: Ako model koristi tehnike koje ga Äine previÅ¡e konzervativnim.  \n",
        "\n",
        "#### Za **Overfitting**:  \n",
        "- **Koristite regularizaciju**: \"Kaznite\" model ako postane previÅ¡e sloÅ¾en.  \n",
        "- **Smanjite broj obeleÅ¾ja**: Izbacite nebitne informacije (npr. \"boja majice\" nije bitna za dijagnozu bolesti).  \n",
        "- **PoveÄ‡ajte koliÄinu podataka**: ViÅ¡e primera = manje Å¡anse da model zapamti Å¡um, tj. da se preprilagodi pojedinaÄnim podacima.  \n",
        "- **Koristite cross-validation**: Proverite da li model dobro radi na svim delovima podataka.  \n",
        "\n",
        "---\n",
        "\n",
        "### â“ **Interaktivno pitanje**  \n",
        "*Å ta je ovo?*  \n",
        "- Model ima 99% taÄnosti na treningu, 50% na testu.\n",
        "<details>\n",
        "  <summary>Klikni za odgovor</summary>\n",
        "  âœ…   Overfitting\n",
        "</details>  \n",
        "- Model ima 60% taÄnosti i na treningu i na testu.\n",
        "<details>\n",
        "  <summary>Klikni za odgovor</summary>\n",
        "  âœ…   Underfitting\n",
        "</details>  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸŒ **ZaÅ¡to je ovo vaÅ¾no?**  \n",
        "- **Preprilagodavanje** i **podprilagodavanje** su glavni razlozi loÅ¡ih performansi modela u stvarnom svetu.  \n",
        "- Bez razumevanja, moÅ¾ete izgubiti nedelje radeÄ‡i na modelu koji radi samo u laboratoriji.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ **Sumirano**  \n",
        "```  \n",
        "BALANS = GOLDILOCKS ZONA ğŸŒŸ  \n",
        "Underfitting: âŒ Premalo uÄenja.  \n",
        "Overfitting: âŒ PreviÅ¡e uÄenja.  \n",
        "Idealno: âœ… Model uhvati prave obrasce, ignoriÅ¡e Å¡um.  \n",
        "```  \n",
        "\n"
      ],
      "metadata": {
        "id": "-N-fuQWa9Py7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Mera performanse**\n",
        "---"
      ],
      "metadata": {
        "id": "bQjrOxSd-yGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ğŸŒŸ **Analogija**  \n",
        "*Zamisli da si ribolovac. Kako meriÅ¡ svoj ribolovaÄki uspeh?*  \n",
        "  1. Koliko si ukupno riba upecao?\n",
        "  2. Koliko riba je bilo preko 3kg u tvom ulovu?  \n",
        "  3. Koliko je tvoja tehnika dobra, koliko puta si upecao riba teÅ¾ine preko 3kg kada si imao Å¡ansu za to?\n",
        "  4. Nekom kombinacijom broja riba preko 3kg i iskoriÅ¡Ä‡enih Å¡ansi za to?\n",
        "\n",
        "  Da li Å¾eliÅ¡ samo da pecaÅ¡ Å¡to viÅ¡e riba ili ti je vaÅ¾nije da budu prave teÅ¾ine ili je ipak vaÅ¾nije da oceniÅ¡ svoju tehniku?\n",
        "\n",
        "  Isto je i u predstavljanju rezultata tvog modela - **Izbor metrike zavisi od tvog cilja!**\n",
        "---\n",
        "### ğŸ“š**RazliÄite metrike za razliÄite zadatke**  \n",
        "- **Klasifikacija** (kategorije): TaÄnost, preciznost, odziv, F1.  \n",
        "- **Regresija** (brojevi): MSE, RMSE, MAE, RÂ².  \n",
        "\n",
        "###  **Evaluacija za klasifikaciju**  \n",
        "#### 1. **Konfuziona matrica**  \n",
        "- Tabela koja prikazuje taÄna i pogreÅ¡na predviÄ‘anja.\n",
        "\n",
        "![img/1/confusion_matrix.png](img/1/confusion_matrix.png)\n",
        "\n",
        "#### 2. **Metrike**  \n",
        "- 1. **TaÄnost (Accuracy)** â€“ Koliko ukupno taÄno klasifikujemo?   \n",
        "     `TP + TN / (TP + FP + TN + FN)`\n",
        "\n",
        "    - Ako posedujemo 1000 mejlova, a model ispravno oznaÄi 900 njih (bilo kao spam ili kao regularne), taÄnost je 90%.  \n",
        "    - Problem? Ako je 950 mejlova regularno i 50 mejlova spam, model moÅ¾e postiÄ‡i visoku taÄnost jednostavno tako Å¡to skoro nikad ne oznaÄi mejl kao spam ali to nije ispravna pretpostavka mere performanse.  \n",
        "\n",
        "- 2. **Preciznost (Precision)**: â€“ Koliko su oznaÄeni spam mejlovi zaista spam?  \n",
        "      `TP / (TP + FP)`\n",
        "    \n",
        "    - Ako model oznaÄi 100 mejlova kao spam, a samo 60 su zaista spam, preciznost je 60%.\n",
        "    - Problem? Ako je preciznost niska, izgubiÄ‡eÅ¡ vaÅ¾ne mejlove jer su pogreÅ¡no oznaÄeni kao spam, sa druge strane, ne vodimo raÄuna o tome koliko spam mejlova nismo prepoznali.\n",
        "\n",
        "- 3. **Odziv (Recall)**:  â€“ Koliko stvarnog spama prepoznamo?   \n",
        "      `TP / (TP + FN)`\n",
        "\n",
        "    - Ako u inboxu ima 80 pravih spam mejlova, a model oznaÄi samo 60, osetljivost je 75%.  \n",
        "    - Problem? Ako je osetljivost niska, mnogo spama Ä‡e i dalje zavrÅ¡iti u tvojoj glavnoj poÅ¡ti, ne vodimo raÄuna o tome koliko regularnih mejlova smo oznaÄili kao spam.\n",
        "\n",
        "- 4. **F1-Score**: Harmonijska sredina preciznosti i odziva â†’ Balans izmeÄ‘u njih.  \n",
        "      `2 * Precision * Recall / (Precision + Recall)`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###  **Evaluacija za regresiju**  \n",
        "#### 1. **MSE (Mean Squared Error)**  \n",
        "-  Prosek kvadrata greÅ¡aka izmeÄ‘u predviÄ‘anja i stvarnih vrednosti.  \n",
        "- **Primer**: Ako model predvidi cenu stana kao 200.000â‚¬, a stvarna je 210.000â‚¬, greÅ¡ka je 10.000Â² = 100.000.000.  \n",
        "\n",
        "    $$\n",
        "    MSE = \\frac{1}{N} \\sum (y_i - \\hat{y}_i)^2\n",
        "    $$\n",
        "  \n",
        "\n",
        "- $\\ y_i -$  Stvarna vrednost   \n",
        "- $\\hat{y}_i -$ Prediktivna vrednost\n",
        "\n",
        "#### 2. **MAE (Mean Absolute Error)**  \n",
        "- Prosek apsolutnih greÅ¡aka â†’ LakÅ¡e za tumaÄenje.  \n",
        "- **Primer**: Za isti stan, greÅ¡ka je |200.000 - 210.000| = 10.000.  \n",
        "\n",
        "    $$\n",
        "    MAE = \\frac{1}{N} \\sum |y_i - \\hat{y}_i|\n",
        "    $$\n",
        "\n",
        "- $\\ y_i -$  Stvarna vrednost   \n",
        "- $\\hat{y}_i -$ Prediktivna vrednost\n",
        "\n",
        "#### 3. **RÂ² (R-squared)**  \n",
        "- Koliko dobro model objaÅ¡njava varijaciju podataka (0 = loÅ¡e, 1 = savrÅ¡eno).  \n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
        "$$\n",
        "\n",
        "- $\\ y_i -$  Stvarna vrednost   \n",
        "- $\\hat{y}_i -$ Prediktivna vrednost\n",
        "- $\\bar{y} -$ Srednja vrednost podataka\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸŒ **PraktiÄni saveti**  \n",
        "1. **Obratite paÅ¾nju na balansiranost klasa i poÄnite sa jednostavnim metrikama**.  \n",
        "2. **Koristite cross-validation** da proverite stabilnost modela.\n",
        "3. **Preciznost** je bitna ako Å¾elite da izbegnete laÅ¾ne alarme.  \n",
        "   **Odziv** je bitan ako Å¾elite da uhvatite Å¡to viÅ¡e sluÄajeva.  \n",
        "\n",
        "---\n",
        "### â“ **Interaktivno pitanje**:  \n",
        "   1. *Ako model za preporuku filmova ima visoku preciznost (90%), ali nizak odziv (30%), Å¡ta to znaÄi?*  \n",
        "    <details>\n",
        "      <summary>Klikni za odgovor</summary>\n",
        "      âœ…   Model retko greÅ¡i kad preporuÄi film, ali propuÅ¡ta mnoge filmove koje bi korisnik voleo.\n",
        "    </details>\n",
        "   2. *Skup podataka je saÄinjen od 95% regularnih i 5% spam mejlova, kakav je model koji ima 95% taÄnosti? Ako mislite da je dobar - zaÅ¡to? Ako mislite da je loÅ¡ - zaÅ¡to i kako biste popravili?*\n",
        "    <details>\n",
        "      <summary>Klikni za odgovor</summary>\n",
        "      âœ…   Beskoristan - Koristimo druge metrike i pokuÅ¡amo da izbalansiramo skup podataka\n",
        "    </details>\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VTLhSiIS4hMF"
      }
    }
  ]
}