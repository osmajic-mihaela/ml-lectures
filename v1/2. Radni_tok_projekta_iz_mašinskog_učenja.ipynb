{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Čišćenje i priprema podataka**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Lc0EJzU0-dAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 🌟 **Analogija**  \n",
        "Zamislite da pravite salatu:  \n",
        "- Ako koristite **pokvareni paradajz** ili **neopranu zelenu salatu**, cela salata će imati loš ukus\n",
        "**Čišćenje podataka je isto** – ako model uči iz neurednih podataka, donosiće loše odluke.  \n",
        "**Cilj**: Ukloniti 'nečistoće' i pripremiti podatke da budu **konzistentni, potpuni i korisni**.\n",
        "\n",
        "---\n",
        "\n",
        "### 📚 **Definicija**  \n",
        "Proces transformacije \"sirovih\" podataka u oblik pogodan za mašinsko učenje.\n",
        "\n",
        "**Ključni koraci**:  \n",
        "1. **Popunjavanje nedostajućih vrednosti** (Missing Values).  \n",
        "2. **Uklanjanje autlajera** (Outliers).  \n",
        "3. **Kodiranje kategorijskih promenljivih** .  \n",
        "4. **Normalizacija** (skaliranje brojeva na zajednički opseg).  \n",
        "5. **Uklanjanje duplikata**.  \n",
        "\n",
        "---\n",
        "\n",
        "### 🧹 **Koraci čišćenja i pripreme (sa primerima)**  \n",
        "\n",
        "#### 1. **Nedostajući podaci (Missing Values)**  \n",
        "- **Problem**: Prazna polja u tabeli (`NaN`).  \n",
        "- **Rešenja**:  \n",
        "  - **Popuniti ih**: npr. srednjom vrednošću, medijanom, interpolacijom, vrednošću najsličnije instance...\n",
        "  - **Izbaciti redove**: Ako je mali procenat nedostajućih vrednosti   \n",
        "\n",
        "\n",
        "#### 2. **Autlajeri (Outliers)**  \n",
        "- **Problem**: Vrednosti koje ekstremno odstupaju (npr. stan od 200 m² u gradu gde su prosečni stanovi 70 m²).  \n",
        "- **Rešenja**:  \n",
        "  - **Izbaciti ih**: Ako su greške (npr. pogrešno uneta vrednost).  \n",
        "  - **Zameniti graničnim vrednostima**: Npr. postaviti maksimum na 100 m².  \n",
        "\n",
        "#### 3. **Kodiranje kategorijskih promenljivih**  \n",
        "- **Problem**: Modeli ne razumeju tekst (npr. \"Beograd\", \"Novi Sad\").  \n",
        "- **Rešenja**:  \n",
        "  - **Label Encoding**: \"Beograd\" → 1, \"Novi Sad\" → 2.  \n",
        "  - **One-Hot Encoding**: Svaka kategorija postaje posebna binarna vrednost (0 ili 1) u nizu (vektoru) svih vrednosti. Za dva moguća grada Beograd i Novi Sad, Beograd možemo predstaviti kao [1,0], a Novi Sad kao [0, 1]. Generalno, svaka vrednost je predstavljena vektorom gde je na njemu odgovarajućoj poziciji 1, a na ostalim pozicijama je 0. ->  (Beograd: [1,0], Novi Sad: [1,0]).  \n",
        "- *Prevodite reči na jezik koji računar razume (brojeve).*  \n",
        "\n",
        "#### 4. **Normalizacija**  \n",
        "- **Problem**: Različiti opsezi (npr. kvadratura: 50–200 m², cena: 50.000–500.000€).  \n",
        "- **Rešenje**: Skalirajte sve brojeve na opseg 0–1.  \n",
        "- **Analogija**: *Kao da sve sastojke isečete na sličnu ili srazmernu veličinu da ravnomerno prođu kroz proces kuvanja.*  \n",
        "\n",
        "#### 5. **Duplikati**  \n",
        "- **Problem**: Isti podaci uneti više puta.  \n",
        "- **Rešenje**: Izbacivanje ponavljanja.  \n",
        "\n",
        "---\n",
        "\n",
        "### 💡 **Zašto je ovaj proces bitan?**  \n",
        "1. **Tačnost modela**:  \n",
        "   - *Loši podaci → Loša predviđanja.* - *Garbage in, garbage out*\n",
        "   - *Primer:* Ako model vidi da neki stanovi imaju kvadraturu 0 m², naučiće pogrešne veze.  \n",
        "\n",
        "2. **Brzina i efikasnost**:  \n",
        "   - Čist skup podataka smanjuje vreme obuke i memorijsko opterećenje.  \n",
        "\n",
        "3. **Sprečavanje pristrasnosti (Bias)**:  \n",
        "   - Ako podaci sadrže sistematske greške (npr. svi stanovi su iz jednog naselja), model će biti pristrasan.  \n",
        "\n",
        "4. **Generalizacija**:  \n",
        "   - Dobro pripremljeni podaci omogućavaju modelu da radi i na **novim podacima**.  \n",
        "---\n",
        "\n",
        "### 🌍 **Primer iz prakse: Predviđanje cena automobila**  \n",
        "1. **Nedostajući podaci**: 10% automobila nema godište → zameni medianom (2015).  \n",
        "2. **Autlajeri**: Jedan automobil ima godište 3021 (očigledna greška) → izbaci.  \n",
        "3. **Kategorijska promenljiva**: Boja → One-Hot Encoding\n",
        "4. **Skaliranje**: Cena od 5.000–50.000€ → skaliraj na 0–1.  \n",
        "\n",
        "**Efekat**: Model postaje tačniji nakon čišćenja!  \n",
        "\n",
        "---\n",
        "\n",
        "###  \n",
        "```  \n",
        "PRE ČIŠĆENJA:  \n",
        "| Model   | Godište | Cena   | Boja   |  \n",
        "|---------|---------|--------|--------|  \n",
        "| Golf    | 2010    | 8000   | Crvena |  \n",
        "| Passat  | NaN     | 15000  | Plava  |  \n",
        "| Polo    | 3021    | 500    | Crna   |  \n",
        "\n",
        "POSLE ČIŠĆENJA:  \n",
        "| Model   | Godište | Cena (0-1) | Crvena | Plava | Crna   |  \n",
        "|---------|---------|------------|--------|-------|--------|  \n",
        "| Golf    | 2010    | 0.16       | 1      | 0     | 0      |  \n",
        "| Passat  | 2015    | 0.30       | 0      | 1     | 1      |  \n",
        "```  \n",
        "\n",
        "---\n",
        "\n",
        "### ❓ **Interaktivno pitanje**  \n",
        "*Šta biste uradili sa kolonom gde 50% podataka nedostaje?*  \n",
        "- **A)** Izbaciti celu kolonu.  \n",
        "- **B)** Popuniti prosekom.  \n",
        "- **C)** Istražiti zašto nedostaje i doneti odluku.\n",
        "- **D)** Izbaciti sve redove sa nedostajućim vrednostima.\n",
        "<details>\n",
        "  <summary>Klikni za odgovor</summary>\n",
        "  ✅  C – kontekst je ključan!\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "### 🚫 **Česte greške**  \n",
        "1. **Previše čišćenja**: Uklanjanje autlajera koji su zapravo validni (npr. retki ali važni slučajevi prevara).  \n",
        "2. **Ignorisanje konteksta**: Popunjavanje nedostajućih vrednosti na način koji iskrivljuje priču (npr. zameniti nedostajuću platu prosekom, iako su podaci grupisani po radnim mestima).  \n",
        "3. **Zanemariti nebalansiranost skupova**: Ako su klase nejednako zastupljene (npr. 95% pozitivnih i 5% negativnih primera), model može naučiti da uvek predviđa dominantnu klasu, što dovodi do loše generalizacije.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qthxj19884fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Princip evaluacije:**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "qqoPW7E4-lwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Napomena: Pri obučavanju modela upoređujemo stvarne i predviđene vrednosti modela i dobijamo kvantitativnu vrednost performansi modela - meru performanse (Više o tome u nastavku), ali pre obučavanja moramo skup podataka da podelimo na grupe shodno njihovim svrhama.    \n",
        "U literaturi princip evaluacije i mera performanse se uglavnom nalaze pod naslovom \"Evaluacija modela\". Kako bismo ispratili tok rada jednog ML projekta mi ćemo prvo pričati o principu evaluacije kao procesu podele skupa podataka, onda o obučavanju, a nakon toga o merama perfomanse modela.\n",
        "\n",
        "### 🌟 **Analogija**  \n",
        "*Zamislite da učite za ispit iz matematike:*  \n",
        "- **Trening skup**: Udžbenik iz kog vežbate.  \n",
        "- **Validacioni skup**: Probni testovi koje radite pre ispita da proverite gde grešite.  \n",
        "- **Test skup**: Sam ispit – provera na zadacima koje do tad niste videli, tek tu vidite koliko ste stvarno naučili.  \n",
        "\n",
        "**Cilj:** Provera generalizacije modela - da li radi i na **novim, neviđenim podacima** (a ne samo na onima koje je 'naučio napamet').\n",
        "\n",
        "---\n",
        "\n",
        "### 📚 **Definicija**  \n",
        "\n",
        "U nastavku ćemo navesti dva najčešća principa evaluacije (podele svih raspoloživih primera iz skupa podataka):\n",
        "\n",
        "#### 1. **Trening/Validacioni/Test skup**  \n",
        "- **Trening skup** (70–80% podataka):  \n",
        "  - Podaci na kojima model **uči** (nalazi obrasce).  \n",
        "  - *Analogija:* Vežbanje zadataka iz udžbenika.  \n",
        "- **Validacioni skup** (10–15%):  \n",
        "  - Podaci za **podešavanje** modela (odabir najboljih hiperparametara).  \n",
        "  - *Analogija:* Probni testovi – menjate strategiju učenja ako rezultati nisu zadovoljavajući.  \n",
        "- **Test skup** (10–15%):  \n",
        "  -  Podaci za **finalnu proveru** performansi.  \n",
        "  - *Analogija:* Ispit u realnim uslovima – test znanja na nikad viđenim podacima.  \n",
        "\n",
        "```  \n",
        "Podaci → [Trening (70%)] → [Validacioni (15%)] → [Test (15%)]  \n",
        "```\n",
        "\n",
        "\n",
        "#### 2. **K-unakrsna validacija (K-Fold Cross-Validation)**  \n",
        "- Podela podataka na **K jednakih delova**. Model se trenira **K puta** – svaki put se jedan deo koristi za validaciju, ostali za trening.  \n",
        "- **Analogija:**  \n",
        "  Postoji 5 probnih testova. Svaki put izaberete 1 test da radite, a ostala 4 koristite za učenje. Na kraju, uprosečite rezultate svih 5 testova.  \n",
        "\n",
        "```  \n",
        "K = 5  \n",
        "1. Iteracija: Trening (Fold 2-5) → Validacija (Fold 1)  \n",
        "2. Iteracija: Trening (Fold 1,3-5) → Validacija (Fold 2)  \n",
        "...  \n",
        "5. Iteracija: Trening (Fold 1-4) → Validacija (Fold 5)  \n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 🎯 **Ključne razlike između metoda**  \n",
        "| Metoda               | Prednosti                          | Nedostaci                     | Kada koristiti?              |  \n",
        "|----------------------|------------------------------------|-------------------------------|------------------------------|  \n",
        "| **Trening/Valid/Test** | Brža i jednostavnija.             | Manje pouzdana ako je malo podataka. | Veliki skupovi podataka.     |  \n",
        "| **K-Fold**           | Smanjuje rizik od loše podele podataka. | Spora i zahteva više resursa. | Mali skupovi ili kritični zadaci. |  \n",
        "\n",
        "---\n",
        "\n",
        "### 🌍 **Primer**  \n",
        "\n",
        "Pravite model za prepoznavanje bolesti na osnovu rendgena:\n",
        "\n",
        "1. **Trening skup**: 800 slika – model uči kako izgledaju obolela i zdrava tkiva.  \n",
        "2. **Validacioni skup**: 100 slika – podešavate parametre (sprečavate preprilagodavanje, tj. napamet situaciju napamet naučenih 800 slika - overfitting (O tome više u sledećem poglavlju)).  \n",
        "3. **Test skup**: 100 slika – konačno merenje koliko je model pouzdan.\n",
        "\n",
        "Sprečava preprilagodavanje i daje realnu sliku performansi\n",
        "\n",
        "**K-Fold (K=5):**  \n",
        "- Podelite 1000 slika na 5 grupa.  \n",
        "- Svaka grupa je validacioni skup tačno jednom.  \n",
        "- Prosečna tačnost svih 5 testova = realnija procena.  \n",
        "\n",
        "\"Zlatni standard\" za male skupove – svaki podatak dobije ulogu u treningu i validaciji.\n",
        "\n",
        "---\n",
        "\n",
        "### ❓ **Interaktivno pitanje**  \n",
        "*Šta biste odabrali za ove situacije?*  \n",
        "- **A)** Imate 100.000 podataka i želite brzu evaluaciju.  \n",
        "<details>\n",
        "  <summary>Klikni za odgovor</summary>\n",
        "  ✅  Trening/Valid/Test\n",
        "</details>\n",
        "- **B)** Imate samo 500 podataka i želite maksimalno pouzdane rezultate.  \n",
        "<details>\n",
        "  <summary>Klikni za odgovor</summary>\n",
        "  ✅  K-Fold\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "### 🚫 **Česte greške**  \n",
        "1. **Testiranje na trening podacima**: Koristite udžbenik kao ispit – model će imati lažno visoke performanse.  \n",
        "2. **Curenje podataka (Data Leakage)**: Slučajno korišćenje test podataka za podešavanje modela – videli ste ispit pre nego što ga radite.  \n",
        "\n"
      ],
      "metadata": {
        "id": "YJBvWF_mxb6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Obučavanje modela**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uboQR-eZ-pxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 🌟 **Analogija**  \n",
        "*Zamislite da učite studenta matematike:*\n",
        "1. **Delite zadatke u tri kategorije** : za učenje (trening skup), za proveru (validacioni skup) i za krajnje testiranje (test skup)\n",
        "2. **Zadatke iz udžbenika (trening podaci) delite na lekcije (batch-eve)**  \n",
        "2. **Proveravate rešenja** i objašnjavate greške (validacioni skup).  \n",
        "3. **Ponavljate** dok ne nauči (epohu po epohu ).  \n",
        "4. **Testirate ga na novim zadacima** (test skup).  \n",
        "\n",
        "**Treniranje modela je isto** – algoritam 'uči' iz podataka da bi donosio tačna predviđanja.\n",
        "\n",
        "---\n",
        "\n",
        "Pre svega potrebno je izabrati model, cilj obučavanja modela je učenje parametra koji će za novi podatak dati što tačniju izlaznu vrednost.\n",
        "\n",
        "\n",
        "### 📚 **Šta se dešava tokom obučavanja?**  \n",
        "1. **Model prima podatke**:  \n",
        "   - **Obeležja (X)**: Ulazne informacije (npr. kvadratura, lokacija stana).  \n",
        "   - **Labela (y)**: Izlaz koji želimo da predvidi (npr. cena stana).  \n",
        "\n",
        "2. **Inicijalizacija parametara**:  \n",
        "   - Model počinje sa **nasumičnim pretpostavkama** (npr. težinski koeficijenti u linearnoj regresiji).  \n",
        "   - *Analogija:* Zamislite da je student pre bilo kakvog učenja osmislio svoju metodu rešavanja zadataka.  \n",
        "\n",
        "3. **Predviđanje i greška**:  \n",
        "  - Model vrši proces **predviđanja** (npr. cena = 200.000€).  \n",
        "  - **Greška (loss)** se računa poređenjem sa stvarnom vrednošću instance iz trening skupa (npr. stvarna cena = 210.000€ → greška = 10.000€).  \n",
        "  - Ujedno se proverava i mera performanse na validacionom skupu.\n",
        "  - *Analogija:* Student prelazi lekciju iz udžbenik. Nakon što je nauči, proverava svoje znanje na zadacima za proveru.  \n",
        "\n",
        "4. **Optimizacija**:  \n",
        "   - Model **podešava parametre** kako bi smanjio grešku kojim neznatno menja vrednost parametra u smeru koji smanjuje grešku rezultata (npr. koristi **gradijentni spust**).  \n",
        "   - *Analogija:* Student prilagodi metode rešavanja nakon što vidi gde greši.\n",
        "\n",
        "  🚩 **Napomena** : Model podešava parametre u odnosu na greške sa trening skupa, provera na validacionom skupu je provera koliko model greši u **generalizaciji** (sposobnost modela da uspešno primeni naučeno i na novim situacijama, a ne samo na onim što je već \"zapamtio\").\n",
        "\n",
        "   Greške na trening skupu služe za obučavanje modela, tj. podešavanje parametara. Praćenje greške na validacionom skupu služi za podešavanje hiperparametara modela koje korisnik namešta ručno pre početka obučavanja.\n",
        "\n",
        "  1) **Parametri** - računaju se sami, podešavaju pomoću algoritma koji se oslanja na grešku na trening skupu  \n",
        "  2) **Hiperparametri** - korisnik namešta pre početka obučavanja, ukoliko je već obučio model oslanja se na rezultate sa validacionog skupa (Još jedna napomena: I ovaj proces se automatizuje, ali nekad to nije moguće to uraditi zbog resursa. Kako bi Vam lakše bilo da razumete razliku, ostanimo pri tome da korisnik to sam radi)\n",
        "\n",
        "5. **Ponavljanje (epohe)**:  \n",
        "   - Proces učenja se ponavlja ispočetka, dok greška ne postane dovoljno mala ili se dostigne maksimalan broj epoha.  \n",
        "\n",
        "6. **Testiranje**  \n",
        "   - Testiramo model na test podacima koje će videti po prvi put.  \n",
        "\n",
        "---\n",
        "\n",
        "### ⚙️ **Kako model postaje bolji?**  \n",
        "- **Parametri se fino podešavaju**: Svaka epoha smanjuje grešku.  \n",
        "- **Primer za linearnu regresiju**:  \n",
        "  - Početak: `cena = 3 * kvadratura + 10000` (loše).  \n",
        "  - Kraj: `cena = 2.5 * kvadratura + 15000` (tačnije).  \n",
        "\n",
        "  `2.5` i `15000` su naučeni parametri modela, `kvadratura` je atribut/obeležje (x), `cena` je izlaz/labela/ciljno obeležje (y)\n",
        "\n",
        "```  \n",
        "Korak 1: Inicijalizacija  \n",
        "Model: cena = 3 * kvadratura + 10000 → greška = 50.000  \n",
        "\n",
        "Korak 2: Podešavanje težina  -> epoha 1\n",
        "Model: cena = 2.8 * kvadratura + 12000 → greška = 30.000  \n",
        "\n",
        "Korak 3: Ponavljanje  -> epoha 2\n",
        "Model: cena = 2.5 * kvadratura + 15000 → greška = 10.000  \n",
        "```  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Ključni koncepti u procesu**  \n",
        "\n",
        "#### 1. **Loss Function (Funkcija greške)**  \n",
        "- Metrika koja meri koliko su predviđanja loša poređenjem izračunate i stvarne izlazne vrednosti.  \n",
        "- **Primeri**:  \n",
        "  - **MSE** (Mean Squared Error): Za regresiju – prosečna kvadratna greška.  \n",
        "  - **Cross-Entropy**: Za klasifikaciju – kažnjava pogrešne klasifikacije.   \n",
        "\n",
        "#### 2. **Optimizacija (Gradijentni spust)**  \n",
        "- Algoritam koji pronalazi **minimum funkcije greške** podešavanjem parametara.  \n",
        "- **Kako radi**:  \n",
        "  1. Računa **gradijent** (nagib funkcije greške).  \n",
        "  2. Pomeri parametre u smeru suprotnom od gradijenta (npr. \"nizbrdo\").  \n",
        "- **Analogija**: Zamislite da se spuštate niz brdo u magli – pratite nagib (gradijent) da biste stigli do dna (minimalne greške).  \n",
        "\n",
        "*Više o tome u narednim lekcijama*\n",
        "\n",
        "#### 3. **Epohe i Batch-evi**  \n",
        "- **Epoha**: Jedan prolazak kroz **ceo trening skup**.  (npr. 3,168 primera)\n",
        "- **Batch**: Manji podskup podataka korišćen u jednoj iteraciji (npr. 32 primera).  \n",
        "- **Analogija**:  \n",
        "  - **Epoha**: Pročitati ceo udžbenik jednom.  \n",
        "  - **Batch**: Pročitati jednu lekciju.  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### 🚫 **Izazovi tokom treniranja**  \n",
        "1. **Overfitting**: Model nauči napamet trening podatke (student koji je napamet naučio samo zadatke iz zbirke).  \n",
        "2. **Underfitting**: Model je previše jednostavan (student koji ne razume osnove).  \n",
        "3. **Stagnacija**: Greška se ne pada i pored ažuriranja parametara – možda je potrebno promeniti model.  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 🌍 **Primer: Prepoznavanje rukopisa**  \n",
        "1. **Ulaz**: Slika broja (28x28 piksela).  \n",
        "2. **Treniranje**:  \n",
        "   - Model uči da poveže piksele sa brojevima (0-9).  \n",
        "   - Optimizuje težine da minimizuje grešku.  \n",
        "3. **Rezultat**: Nakon 10 epoha, model tačno prepoznaje 95% brojeva.  \n",
        "\n",
        "---\n",
        "\n",
        "### ❓ **Interaktivno pitanje**  \n",
        "Šta se desilo ako model ima izuzetno malu grešku na trening skupu, ali veliku na testu?\n",
        "  <details>\n",
        "    <summary>Klikni za odgovor</summary>\n",
        "    ✅   Overfitting – model ne može da generalizuje\n",
        "  </details>\n",
        "\n",
        "---\n",
        "\n",
        "### 🎯 **Sumirano**  \n",
        "```  \n",
        "UČENJE = PRAVLJENJE I POPRAVLJANJE GREŠAKA 📉  \n",
        "1. Probaj → 2. Izmeri grešku → 3. Podesi parametre → 4. Ponovi dok ne savladaš.  \n",
        "```  \n",
        "\n"
      ],
      "metadata": {
        "id": "wySvhx0n9Kwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Overfitting i Underfitting**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GPDNJ22u-uDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 🌟 **Analogija**  \n",
        "*Zamislite da učite da crtate čoveka:*  \n",
        "- **Underfitting**: Nacrtate Čiča Glišu (previše jednostavno, nema detalja).  \n",
        "- **Overfitting**: Nacrtate svaki detalj, ali samo za čoveka kog ste videli – ne možete nacrtati druge ljude.  \n",
        "\n",
        "**Cilj**: Naći balans – crtež koji prepoznaje osobu, ali sa dovoljno detalja.\n",
        "\n",
        "---\n",
        "Pogledaj sliku ispod.\n",
        "\n",
        "### 📚 **Underfitting (Potprilagodavanje)**  \n",
        "- Model je **previše jednostavan** da uhvati obrasce u podacima.  \n",
        "- **Analogija**:  \n",
        "  - Kao da pokušavate da rešite matematički problem samo sa osnovnim računanjem.  \n",
        "  - Ili da pevate pesmu samo u jednom tonu – nema dinamike.  \n",
        "- **Znaci**:  \n",
        "  - Loše performanse i na **trening** i na **validacionom** skupu.  \n",
        "  - Model ne uči ništa korisno.  \n",
        "- **Uzroci**:  \n",
        "  - Premalo složenosti (npr. linearni model za nelinearne podatke).  \n",
        "  - Premalo podataka za obuku.  \n",
        "  - Premalo obeležja.\n",
        "\n",
        "---\n",
        "\n",
        "### 📚 **Overfitting (Preprilagodavanje)**  \n",
        "- Model **nauči šum i detalje iz trening podataka** i ne može da generalizuje.  \n",
        "- **Analogija**:  \n",
        "  - Student uči napamet sve primere iz zbirke, ali ne razume kako da reši novi zadatak.  \n",
        "  - Zapamtite svaki korak GPS navigacije za jednu rutu – ako se promeni put, izgubljeni ste.  \n",
        "- **Znaci**:  \n",
        "  - Savršena tačnost na **trening**, ali loša na **validacionom**.  \n",
        "  - Model \"prati\" svaku tačku u podacima.  \n",
        "- **Uzroci**:  \n",
        "  - Previše složen model.  \n",
        "  - Predugo pušten proces obučavanja.  \n",
        "  - Previše obeležja.\n",
        "\n",
        "![img/1/overfitting-underfitting.jpg](img/1/overfitting-underfitting.jpg)\n",
        "\n",
        "*Regulacija je tehnika sprečavanja overfitting-a dodatnim kažnjavanjem modela u loss funkciji, sprečavajući na taj način \"učenje napamet\"*\n",
        "\n",
        "---\n",
        "\n",
        "### 📚 **Bias-Variance Tradeoff**  \n",
        "**Bias** (pristrasnost) pokazuje koliko model pojednostavljuje problem – da li model pravi previše jake pretpostavke i ignoriše važne obrasce u podacima, ne uči dobro.   \n",
        "**Variance**  (varijansa) pokazuje koliko su predikcije modela osetljive na promene u trening podacima.\n",
        "\n",
        "- **Underfitting** = **Visok bias** (model pravi jake pretpostavke - pojednostavljuje).  \n",
        "- **Overfitting** = **Visoka varijansa** (model je previše osetljiv na podatke - previše se uklapa u podatke).  \n",
        "- **Balans**: Model koji uhvati prave obrasce (dovoljno se uklopi u podatke), a ignoriše šum.  \n",
        "\n",
        "**Analogija**:  \n",
        "*Kao da podesite radio antenu:*  \n",
        "- **Underfitting**: Antena hvata sve šumove, ali nijedna stanica nije čista.\n",
        "- **Overfitting**: Antena uhvati samo jednu stanicu, ali jasno.\n",
        "- Potrebno je naći meru tako da se uhvati dovoljno stanica, sa dovoljnom čistinom\n",
        "\n",
        "*Ako zamislimo previđanje modela kao pogađanje u metu*\n",
        "1. Visok bias, niska varijansa → Promašuje metu, ali je precizan na pogrešnom mestu (Underfitting).\n",
        "2. Nizak bias, visoka varijansa → Ponekad pogodi, ali su hici raštrkani (Overfitting).\n",
        "3. Visok bias, visoka varijansa → Ništa ne funkcioniše (loš model).\n",
        "4. Nizak bias, niska varijansa → Idealna situacija!\n",
        "\n",
        "![img/1/bias-variance.png](img/1/bias-variance.png)\n",
        "\n",
        "---\n",
        "\n",
        "### 🛠️ **Kako se boriti protiv ovih problema?**  \n",
        "#### Za **Underfitting**:  \n",
        "- **Povećajte složenost modela**: Koristite nelinearne modele (npr. neuronske mreže).  \n",
        "- **Dodajte više obeležja**: Npr. ne samo \"kvadratura\", već i \"lokacija\", \"broj soba\".  \n",
        "- **Smanjite regularizaciju**: Ako model koristi tehnike koje ga čine previše konzervativnim.  \n",
        "\n",
        "#### Za **Overfitting**:  \n",
        "- **Koristite regularizaciju**: \"Kaznite\" model ako postane previše složen.  \n",
        "- **Smanjite broj obeležja**: Izbacite nebitne informacije (npr. \"boja majice\" nije bitna za dijagnozu bolesti).  \n",
        "- **Povećajte količinu podataka**: Više primera = manje šanse da model zapamti šum, tj. da se preprilagodi pojedinačnim podacima.  \n",
        "- **Koristite cross-validation**: Proverite da li model dobro radi na svim delovima podataka.  \n",
        "\n",
        "---\n",
        "\n",
        "### ❓ **Interaktivno pitanje**  \n",
        "*Šta je ovo?*  \n",
        "- Model ima 99% tačnosti na treningu, 50% na testu.\n",
        "<details>\n",
        "  <summary>Klikni za odgovor</summary>\n",
        "  ✅   Overfitting\n",
        "</details>  \n",
        "- Model ima 60% tačnosti i na treningu i na testu.\n",
        "<details>\n",
        "  <summary>Klikni za odgovor</summary>\n",
        "  ✅   Underfitting\n",
        "</details>  \n",
        "\n",
        "---\n",
        "\n",
        "### 🌍 **Zašto je ovo važno?**  \n",
        "- **Preprilagodavanje** i **podprilagodavanje** su glavni razlozi loših performansi modela u stvarnom svetu.  \n",
        "- Bez razumevanja, možete izgubiti nedelje radeći na modelu koji radi samo u laboratoriji.  \n",
        "\n",
        "---\n",
        "\n",
        "### 🎯 **Sumirano**  \n",
        "```  \n",
        "BALANS = GOLDILOCKS ZONA 🌟  \n",
        "Underfitting: ❌ Premalo učenja.  \n",
        "Overfitting: ❌ Previše učenja.  \n",
        "Idealno: ✅ Model uhvati prave obrasce, ignoriše šum.  \n",
        "```  \n",
        "\n"
      ],
      "metadata": {
        "id": "-N-fuQWa9Py7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Mera performanse**\n",
        "---"
      ],
      "metadata": {
        "id": "bQjrOxSd-yGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 🌟 **Analogija**  \n",
        "*Zamisli da si ribolovac. Kako meriš svoj ribolovački uspeh?*  \n",
        "  1. Koliko si ukupno riba upecao?\n",
        "  2. Koliko riba je bilo preko 3kg u tvom ulovu?  \n",
        "  3. Koliko je tvoja tehnika dobra, koliko puta si upecao riba težine preko 3kg kada si imao šansu za to?\n",
        "  4. Nekom kombinacijom broja riba preko 3kg i iskorišćenih šansi za to?\n",
        "\n",
        "  Da li želiš samo da pecaš što više riba ili ti je važnije da budu prave težine ili je ipak važnije da oceniš svoju tehniku?\n",
        "\n",
        "  Isto je i u predstavljanju rezultata tvog modela - **Izbor metrike zavisi od tvog cilja!**\n",
        "---\n",
        "### 📚**Različite metrike za različite zadatke**  \n",
        "- **Klasifikacija** (kategorije): Tačnost, preciznost, odziv, F1.  \n",
        "- **Regresija** (brojevi): MSE, RMSE, MAE, R².  \n",
        "\n",
        "###  **Evaluacija za klasifikaciju**  \n",
        "#### 1. **Konfuziona matrica**  \n",
        "- Tabela koja prikazuje tačna i pogrešna predviđanja.\n",
        "\n",
        "![img/1/confusion_matrix.png](img/1/confusion_matrix.png)\n",
        "\n",
        "#### 2. **Metrike**  \n",
        "- 1. **Tačnost (Accuracy)** – Koliko ukupno tačno klasifikujemo?   \n",
        "     `TP + TN / (TP + FP + TN + FN)`\n",
        "\n",
        "    - Ako posedujemo 1000 mejlova, a model ispravno označi 900 njih (bilo kao spam ili kao regularne), tačnost je 90%.  \n",
        "    - Problem? Ako je 950 mejlova regularno i 50 mejlova spam, model može postići visoku tačnost jednostavno tako što skoro nikad ne označi mejl kao spam ali to nije ispravna pretpostavka mere performanse.  \n",
        "\n",
        "- 2. **Preciznost (Precision)**: – Koliko su označeni spam mejlovi zaista spam?  \n",
        "      `TP / (TP + FP)`\n",
        "    \n",
        "    - Ako model označi 100 mejlova kao spam, a samo 60 su zaista spam, preciznost je 60%.\n",
        "    - Problem? Ako je preciznost niska, izgubićeš važne mejlove jer su pogrešno označeni kao spam, sa druge strane, ne vodimo računa o tome koliko spam mejlova nismo prepoznali.\n",
        "\n",
        "- 3. **Odziv (Recall)**:  – Koliko stvarnog spama prepoznamo?   \n",
        "      `TP / (TP + FN)`\n",
        "\n",
        "    - Ako u inboxu ima 80 pravih spam mejlova, a model označi samo 60, osetljivost je 75%.  \n",
        "    - Problem? Ako je osetljivost niska, mnogo spama će i dalje završiti u tvojoj glavnoj pošti, ne vodimo računa o tome koliko regularnih mejlova smo označili kao spam.\n",
        "\n",
        "- 4. **F1-Score**: Harmonijska sredina preciznosti i odziva → Balans između njih.  \n",
        "      `2 * Precision * Recall / (Precision + Recall)`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###  **Evaluacija za regresiju**  \n",
        "#### 1. **MSE (Mean Squared Error)**  \n",
        "-  Prosek kvadrata grešaka između predviđanja i stvarnih vrednosti.  \n",
        "- **Primer**: Ako model predvidi cenu stana kao 200.000€, a stvarna je 210.000€, greška je 10.000² = 100.000.000.  \n",
        "\n",
        "    $$\n",
        "    MSE = \\frac{1}{N} \\sum (y_i - \\hat{y}_i)^2\n",
        "    $$\n",
        "  \n",
        "\n",
        "- $\\ y_i -$  Stvarna vrednost   \n",
        "- $\\hat{y}_i -$ Prediktivna vrednost\n",
        "\n",
        "#### 2. **MAE (Mean Absolute Error)**  \n",
        "- Prosek apsolutnih grešaka → Lakše za tumačenje.  \n",
        "- **Primer**: Za isti stan, greška je |200.000 - 210.000| = 10.000.  \n",
        "\n",
        "    $$\n",
        "    MAE = \\frac{1}{N} \\sum |y_i - \\hat{y}_i|\n",
        "    $$\n",
        "\n",
        "- $\\ y_i -$  Stvarna vrednost   \n",
        "- $\\hat{y}_i -$ Prediktivna vrednost\n",
        "\n",
        "#### 3. **R² (R-squared)**  \n",
        "- Koliko dobro model objašnjava varijaciju podataka (0 = loše, 1 = savršeno).  \n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
        "$$\n",
        "\n",
        "- $\\ y_i -$  Stvarna vrednost   \n",
        "- $\\hat{y}_i -$ Prediktivna vrednost\n",
        "- $\\bar{y} -$ Srednja vrednost podataka\n",
        "\n",
        "---\n",
        "\n",
        "### 🌍 **Praktični saveti**  \n",
        "1. **Obratite pažnju na balansiranost klasa i počnite sa jednostavnim metrikama**.  \n",
        "2. **Koristite cross-validation** da proverite stabilnost modela.\n",
        "3. **Preciznost** je bitna ako želite da izbegnete lažne alarme.  \n",
        "   **Odziv** je bitan ako želite da uhvatite što više slučajeva.  \n",
        "\n",
        "---\n",
        "### ❓ **Interaktivno pitanje**:  \n",
        "   1. *Ako model za preporuku filmova ima visoku preciznost (90%), ali nizak odziv (30%), šta to znači?*  \n",
        "    <details>\n",
        "      <summary>Klikni za odgovor</summary>\n",
        "      ✅   Model retko greši kad preporuči film, ali propušta mnoge filmove koje bi korisnik voleo.\n",
        "    </details>\n",
        "   2. *Skup podataka je sačinjen od 95% regularnih i 5% spam mejlova, kakav je model koji ima 95% tačnosti? Ako mislite da je dobar - zašto? Ako mislite da je loš - zašto i kako biste popravili?*\n",
        "    <details>\n",
        "      <summary>Klikni za odgovor</summary>\n",
        "      ✅   Beskoristan - Koristimo druge metrike i pokušamo da izbalansiramo skup podataka\n",
        "    </details>\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VTLhSiIS4hMF"
      }
    }
  ]
}